{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4e81a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tabulate\n",
    "#rapidfuzz psycopg2 matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "383a57e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 21:37:24,152 - INFO - Inicio de la extración de datos de AirBnB.\n",
      "2025-05-17 21:37:24,154 - INFO - Ruta del archivo CSV construida con os: \\\\wsl.localhost\\Ubuntu\\home\\y4xul\\Proyecto_ETL\\data\\raw\\Airbnb_Open_Data.csv\n",
      "2025-05-17 21:37:24,164 - INFO - DataFrame 'df_airbnb' predefinido como un DataFrame vacío.\n",
      "2025-05-17 21:37:24,167 - INFO - Intentando cargar el archivo CSV: \\\\wsl.localhost\\Ubuntu\\home\\y4xul\\Proyecto_ETL\\data\\raw\\Airbnb_Open_Data.csv\n",
      "2025-05-17 21:37:25,153 - INFO - Archivo CSV '\\\\wsl.localhost\\Ubuntu\\home\\y4xul\\Proyecto_ETL\\data\\raw\\Airbnb_Open_Data.csv' cargado exitosamente.\n",
      "2025-05-17 21:37:25,155 - INFO - El DataFrame original tiene 102599 filas y 26 columnas.\n",
      "2025-05-17 21:37:25,157 - INFO - Verificando filas duplicadas en df_airbnb.\n",
      "2025-05-17 21:37:25,300 - INFO - Número de filas duplicadas encontradas en df_airbnb: 541\n",
      "2025-05-17 21:37:25,302 - INFO - Iniciando limpieza preliminar y conversión de tipos de datos (versión optimizada).\n",
      "2025-05-17 21:37:25,326 - INFO - Copia de df_airbnb creada como df_cleaned.\n",
      "2025-05-17 21:37:25,327 - INFO - Columnas de df_cleaned normalizadas.\n",
      "2025-05-17 21:37:25,329 - INFO - Cambios en nombres de columnas: {'id': 'id', 'NAME': 'name', 'host id': 'host_id', 'host_identity_verified': 'host_identity_verified', 'host name': 'host_name', 'neighbourhood group': 'neighbourhood_group', 'neighbourhood': 'neighbourhood', 'lat': 'lat', 'long': 'long', 'country': 'country', 'country code': 'country_code', 'instant_bookable': 'instant_bookable', 'cancellation_policy': 'cancellation_policy', 'room type': 'room_type', 'Construction year': 'construction_year', 'price': 'price', 'service fee': 'service_fee', 'minimum nights': 'minimum_nights', 'number of reviews': 'number_of_reviews', 'last review': 'last_review', 'reviews per month': 'reviews_per_month', 'review rate number': 'review_rate_number', 'calculated host listings count': 'calculated_host_listings_count', 'availability 365': 'availability_365', 'house_rules': 'house_rules', 'license': 'license'}\n",
      "2025-05-17 21:37:25,714 - INFO - Columna 'neighbourhood_group': 2 valores estandarizados usando RapidFuzz.\n",
      "2025-05-17 21:37:25,717 - INFO - RapidFuzz aplicado a 'neighbourhood_group'.\n",
      "2025-05-17 21:37:25,727 - INFO - Columna 'neighbourhood_group' convertida a category.\n",
      "2025-05-17 21:37:25,760 - INFO - Columna 'neighbourhood' limpiada (no convertida a category debido a alta cardinalidad: 225).\n",
      "2025-05-17 21:37:25,797 - INFO - Columna 'cancellation_policy' convertida a category.\n",
      "2025-05-17 21:37:25,832 - INFO - Columna 'room_type' convertida a category.\n",
      "2025-05-17 21:37:25,851 - INFO - Columna 'last_review' convertida a datetime.\n",
      "2025-05-17 21:37:25,871 - INFO - Columnas 'host_verification', creada a partir de 'host_identity_verified'.\n",
      "2025-05-17 21:37:25,938 - INFO - Columna 'instant_bookable_flag' creada a partir de 'instant_bookable'.\n",
      "2025-05-17 21:37:26,083 - INFO - Columna 'price' creada a partir de 'price'.\n",
      "2025-05-17 21:37:26,241 - INFO - Columna 'service_fee' creada a partir de 'service_fee'.\n",
      "2025-05-17 21:37:26,263 - INFO - Columnas ['host_identity_verified', 'instant_bookable', 'country', 'country_code', 'license', 'house_rules'] eliminadas de df_cleaned.\n",
      "2025-05-17 21:37:26,266 - INFO - Proceso de limpieza preliminar y conversión de tipos optimizado completado.\n",
      "2025-05-17 21:37:26,267 - INFO - Proceso finalizado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"clean_airbnb_data.log\"), # Nuevo nombre de log\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info(\"Inicio de la extración de datos de AirBnB.\")\n",
    "\n",
    "try:\n",
    "    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    SCRIPT_DIR = os.getcwd()\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(SCRIPT_DIR))\n",
    "RAW_DATA_DIR = os.path.join(BASE_DIR, 'data', 'raw')\n",
    "CSV_FILE_NAME = 'Airbnb_Open_Data.csv'\n",
    "CSV_FILE_PATH = os.path.join(RAW_DATA_DIR, CSV_FILE_NAME)\n",
    "\n",
    "logging.info(f\"Ruta del archivo CSV construida con os: {CSV_FILE_PATH}\")\n",
    "\n",
    "df_airbnb = pd.DataFrame()\n",
    "logging.info(\"DataFrame 'df_airbnb' predefinido como un DataFrame vacío.\")\n",
    "\n",
    "try:\n",
    "    logging.info(f\"Intentando cargar el archivo CSV: {CSV_FILE_PATH}\")\n",
    "    if not os.path.exists(CSV_FILE_PATH):\n",
    "        logging.error(f\"Error: Archivo CSV no encontrado en '{CSV_FILE_PATH}'\")\n",
    "        raise FileNotFoundError(f\"Archivo no encontrado: {CSV_FILE_PATH}\")\n",
    "    df_airbnb = pd.read_csv(CSV_FILE_PATH, low_memory=False)\n",
    "    logging.info(f\"Archivo CSV '{CSV_FILE_PATH}' cargado exitosamente.\")\n",
    "    logging.info(f\"El DataFrame original tiene {df_airbnb.shape[0]} filas y {df_airbnb.shape[1]} columnas.\")\n",
    "except FileNotFoundError:\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logging.error(f\"Ocurrió un error al cargar el CSV '{CSV_FILE_PATH}': {e}\")\n",
    "    raise\n",
    "\n",
    "if not df_airbnb.empty:\n",
    "    logging.info(\"Verificando filas duplicadas en df_airbnb.\")\n",
    "    num_duplicados = df_airbnb.duplicated().sum()\n",
    "    logging.info(f\"Número de filas duplicadas encontradas en df_airbnb: {num_duplicados}\")\n",
    "else:\n",
    "    logging.critical(\"El DataFrame df_airbnb está vacío después de la carga. Terminando el script.\")\n",
    "    # Considerar salir del script si el DataFrame está vacío: exit()\n",
    "\n",
    "# --- Limpieza Preliminar y Conversión de Tipos de Datos (Refactorizado) ---\n",
    "logging.info(\"Iniciando limpieza preliminar y conversión de tipos de datos (versión optimizada).\")\n",
    "df_cleaned = pd.DataFrame()\n",
    "\n",
    "if not df_airbnb.empty:\n",
    "    df_cleaned = df_airbnb.copy()\n",
    "    logging.info(\"Copia de df_airbnb creada como df_cleaned.\")\n",
    "\n",
    "    original_columns = df_cleaned.columns.tolist()\n",
    "    df_cleaned.columns = df_cleaned.columns.str.lower().str.replace(' ', '_', regex=False).str.replace('[^0-9a-zA-Z_]', '', regex=True)\n",
    "    new_columns = df_cleaned.columns.tolist()\n",
    "    logging.info(f\"Columnas de df_cleaned normalizadas.\")\n",
    "    if original_columns != new_columns:\n",
    "        logging.info(f\"Cambios en nombres de columnas: {dict(zip(original_columns, new_columns))}\")\n",
    "    else:\n",
    "        logging.info(\"Nombres de columnas ya estaban normalizados o no requirieron cambios significativos.\")\n",
    "\n",
    "    def clean_string_column(series, col_name):\n",
    "        logging.debug(f\"Limpiando columna string: {col_name}\")\n",
    "        series = series.astype(str).str.strip().replace({'nan': pd.NA, '': pd.NA, 'None': pd.NA})\n",
    "        return series\n",
    "\n",
    "    def to_numeric_column(series, col_name, numeric_type='Int64'):\n",
    "        logging.debug(f\"Convirtiendo columna a numérica ({numeric_type}): {col_name}\")\n",
    "        nulls_before = series.isna().sum()\n",
    "        if numeric_type == 'datetime':\n",
    "            series = pd.to_datetime(series, format='%m/%d/%Y', errors='coerce')\n",
    "        else:\n",
    "            series = pd.to_numeric(series, errors='coerce')\n",
    "            if numeric_type == 'Int64' and not series.empty:\n",
    "                if series.dropna().apply(lambda x: x.is_integer()).all() or series.dropna().empty:\n",
    "                    series = series.astype('Int64')\n",
    "                else:\n",
    "                    logging.warning(f\"Columna '{col_name}' contiene flotantes, no se convertirá a Int64, se mantendrá como float.\")\n",
    "        \n",
    "        coerced_nulls = series.isna().sum() - nulls_before\n",
    "        if coerced_nulls > 0:\n",
    "            logging.warning(f\"Columna '{col_name}': {coerced_nulls} nuevos NaNs/NaTs por coerción.\")\n",
    "        return series\n",
    "\n",
    "    def standardize_categorical_fuzz(series, col_name, choices_list, score_cutoff=85):\n",
    "        logging.debug(f\"Estandarizando columna categórica con RapidFuzz: {col_name}\")\n",
    "        unique_values = series.dropna().unique()\n",
    "        mapping = {}\n",
    "        for val in unique_values:\n",
    "            match = process.extractOne(str(val), choices_list, scorer=fuzz.WRatio, score_cutoff=score_cutoff)\n",
    "            if match:\n",
    "                mapping[val] = match[0]\n",
    "            else:\n",
    "                mapping[val] = val\n",
    "        \n",
    "        original_na_mask = series.isna()\n",
    "        series_mapped = series.map(mapping)\n",
    "        series_mapped[original_na_mask] = pd.NA\n",
    "        \n",
    "        changes = (series.dropna() != series_mapped.dropna()).sum()\n",
    "        if changes > 0:\n",
    "            logging.info(f\"Columna '{col_name}': {changes} valores estandarizados usando RapidFuzz.\")\n",
    "        return series_mapped\n",
    "\n",
    "    try:\n",
    "        numeric_cols_int = ['construction_year', 'minimum_nights', 'number_of_reviews', 'review_rate_number', \n",
    "                            'calculated_host_listings_count', 'availability_365']\n",
    "        \n",
    "        for col in numeric_cols_int:\n",
    "            if col in df_cleaned.columns:\n",
    "                df_cleaned[col] = to_numeric_column(df_cleaned[col], col, 'Int64')\n",
    "            else: logging.warning(f\"Columna '{col}' no encontrada para conversión numérica (Int64).\")\n",
    "\n",
    "        numeric_cols_float = ['lat', 'long', 'reviews_per_month']\n",
    "        for col in numeric_cols_float:\n",
    "            if col in df_cleaned.columns:\n",
    "                df_cleaned[col] = to_numeric_column(df_cleaned[col], col, 'float')\n",
    "            else: logging.warning(f\"Columna '{col}' no encontrada para conversión numérica (float).\")\n",
    "\n",
    "        df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "        df_cleaned['id'] = df_cleaned.index + 1\n",
    "        df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "        df_cleaned['host_id'] = df_cleaned.index + 150000\n",
    "        \n",
    "        string_cols = ['name', 'host_name']\n",
    "        for col in string_cols:\n",
    "            if col in df_cleaned.columns:\n",
    "                df_cleaned[col] = clean_string_column(df_cleaned[col], col)\n",
    "            else: logging.warning(f\"Columna '{col}' no encontrada para limpieza de string.\")\n",
    "\n",
    "        categorical_cols_pre_fuzz = ['neighbourhood_group', 'neighbourhood']\n",
    "        for col in categorical_cols_pre_fuzz:\n",
    "            if col in df_cleaned.columns:\n",
    "                df_cleaned[col] = clean_string_column(df_cleaned[col], col)\n",
    "                if col == 'neighbourhood_group' and col in df_cleaned.columns:\n",
    "                    canonical_groups = ['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island']\n",
    "                    if not df_cleaned[col].dropna().empty:\n",
    "                       df_cleaned[col] = standardize_categorical_fuzz(df_cleaned[col], col, canonical_groups, score_cutoff=80)\n",
    "                       logging.info(f\"RapidFuzz aplicado a '{col}'.\")\n",
    "                    else:\n",
    "                       logging.info(f\"Columna '{col}' está vacía o solo nulos, RapidFuzz no aplicado.\")\n",
    "\n",
    "                nunique_threshold = 50 if col == 'neighbourhood' else 20 \n",
    "                if col in df_cleaned.columns and df_cleaned[col].nunique(dropna=False) < nunique_threshold:\n",
    "                    df_cleaned[col] = df_cleaned[col].astype('category')\n",
    "                    logging.info(f\"Columna '{col}' convertida a category.\")\n",
    "                elif col in df_cleaned.columns:\n",
    "                    logging.info(f\"Columna '{col}' limpiada (no convertida a category debido a alta cardinalidad: {df_cleaned[col].nunique(dropna=False)}).\")\n",
    "\n",
    "            else: logging.warning(f\"Columna '{col}' no encontrada para limpieza categórica.\")\n",
    "\n",
    "        category_cols_direct = ['cancellation_policy', 'room_type']\n",
    "        for col in category_cols_direct:\n",
    "            if col in df_cleaned.columns:\n",
    "                df_cleaned[col] = clean_string_column(df_cleaned[col], col).astype('category')\n",
    "                logging.info(f\"Columna '{col}' convertida a category.\")\n",
    "            else: logging.warning(f\"Columna '{col}' no encontrada para conversión a category.\")\n",
    "        \n",
    "        # Fechas\n",
    "        if 'last_review' in df_cleaned.columns:\n",
    "            df_cleaned['last_review'] = to_numeric_column(df_cleaned['last_review'], 'last_review', 'datetime')\n",
    "            logging.info(\"Columna 'last_review' convertida a datetime.\")\n",
    "        else: logging.warning(\"Columna 'last_review' no encontrada.\")\n",
    "\n",
    "        # Booleanas (con mapeo)\n",
    "        if 'host_identity_verified' in df_cleaned.columns:\n",
    "            verified_map = {'verified': True, 'unconfirmed': False}\n",
    "            df_cleaned['host_verification'] = df_cleaned['host_identity_verified'].map(verified_map).astype('boolean')\n",
    "            logging.info(\"Columnas 'host_verification', creada a partir de 'host_identity_verified'.\")\n",
    "        else: logging.warning(\"Columna 'host_identity_verified' no encontrada.\")\n",
    "\n",
    "        if 'instant_bookable' in df_cleaned.columns:\n",
    "            bookable_map = {'TRUE': True, 'FALSE': False, 'True': True, 'False': False, 'true': True, 'false': False} # Cubrir varias capitalizaciones\n",
    "            df_cleaned['instant_bookable_flag'] = df_cleaned['instant_bookable'].astype(str).str.upper().map(bookable_map).astype('boolean')\n",
    "            logging.info(\"Columna 'instant_bookable_flag' creada a partir de 'instant_bookable'.\")\n",
    "        else: logging.warning(\"Columna 'instant_bookable' no encontrada.\")\n",
    "\n",
    "        currency_cols = {'price': 'price', 'service_fee': 'service_fee'}\n",
    "        for original_col, new_col_numeric in currency_cols.items():\n",
    "            if original_col in df_cleaned.columns:\n",
    "                series_cleaned_str = df_cleaned[original_col].astype(str).str.replace('$', '', regex=False).str.replace(',', '', regex=False).str.strip().replace({'nan': pd.NA, '': pd.NA})\n",
    "                df_cleaned[new_col_numeric] = to_numeric_column(series_cleaned_str, new_col_numeric, 'float')\n",
    "                logging.info(f\"Columna '{new_col_numeric}' creada a partir de '{original_col}'.\")\n",
    "            else: logging.warning(f\"Columna original '{original_col}' no encontrada para procesar moneda.\")\n",
    "\n",
    "        cols_to_drop_original_names = ['host_identity_verified', 'instant_bookable', 'country', 'country_code', 'license', 'house_rules']\n",
    "        \n",
    "        normalized_cols_to_drop = []\n",
    "        for col_name in cols_to_drop_original_names:\n",
    "            normalized_name = col_name.lower().replace(' ', '_').replace('[^0-9a-zA-Z_]', '')\n",
    "            if normalized_name in df_cleaned.columns:\n",
    "                normalized_cols_to_drop.append(normalized_name)\n",
    "            elif col_name in df_cleaned.columns:\n",
    "                normalized_cols_to_drop.append(col_name)\n",
    "\n",
    "        existing_cols_to_drop = [col for col in normalized_cols_to_drop if col in df_cleaned.columns]\n",
    "        if existing_cols_to_drop:\n",
    "            df_cleaned.drop(columns=existing_cols_to_drop, inplace=True, errors='ignore')\n",
    "            logging.info(f\"Columnas {existing_cols_to_drop} eliminadas de df_cleaned.\")\n",
    "        \n",
    "        logging.info(\"Proceso de limpieza preliminar y conversión de tipos optimizado completado.\")\n",
    "\n",
    "    except KeyError as ke:\n",
    "        logging.error(f\"Ocurrió un KeyError durante la limpieza: '{ke}'. Verifica que la columna exista en df_cleaned (posiblemente después de la normalización).\")\n",
    "        logging.error(f\"Columnas disponibles en df_cleaned: {df_cleaned.columns.tolist()}\")\n",
    "        logging.error(f\"Ocurrió un KeyError: '{ke}'. Revisa los nombres de las columnas y la lógica de normalización.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ocurrió un error general durante la limpieza: {e}\", exc_info=True)\n",
    "        logging.error(f\"Ocurrió un error general: {e}\")\n",
    "\n",
    "else:\n",
    "    logging.warning(\"El DataFrame df_airbnb está vacío. No se puede realizar la limpieza.\")\n",
    "\n",
    "logging.info(\"Proceso finalizado exitosamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
